# Gesture Recognition using TensorFlow Lite & OpenCV

## ğŸ“Œ Project Overview
This project is a **real-time gesture recognition system** using **TensorFlow Lite (TFLite)** and **OpenCV**. It utilizes the **MobileNetV1** model for efficient and lightweight classification, making it ideal for **edge devices** like Raspberry Pi, NVIDIA Jetson, or any AI-powered IoT device.

## âœ¨ Why This Project?
Unlike traditional object classifiers, this project is designed for:
- **Edge Computing:** Runs efficiently on low-power devices using **TinyML** and **Edge Impulse**.
- **Optimized Performance:** Uses **TensorFlow Lite** for faster and optimized inference.
- **Real-time Gesture Recognition:** Captures live video feed, processes frames, and predicts gestures instantly.
- **Scalability:** Can be easily adapted for **IoT applications, robotics, smart home controls**, and more.

## ğŸš€ Features
âœ… Uses a **pre-trained MobileNetV1 model** optimized for low-latency inference.
âœ… Supports real-time inference from **webcam or external cameras**.
âœ… Displays predictions live on screen with an easy-to-use **fullscreen UI**.
âœ… Works efficiently on **edge devices** without requiring heavy computational resources.
âœ… Uses **TensorFlow Lite**, reducing **model size and inference time**.

---

## ğŸ“‚ Project Structure
```
ğŸ“ Gesture_Recognition
â”‚â”€â”€ ğŸ“„ main.py                 # Main script to run gesture recognition
â”‚â”€â”€ ğŸ“„ labels.txt              # Class labels for MobileNetV1 model
â”‚â”€â”€ ğŸ“„ mobilenet_v1_1.0_224_quant.tflite # TFLite model file
â”‚â”€â”€ ğŸ“„ README.md               # Project Documentation
```

---

## âš¡ Installation
Ensure you have Python installed. Then, install the required dependencies:
```bash
pip install opencv-python numpy tensorflow
```

---

## ğŸ¯ How to Run
1ï¸âƒ£ Clone this repository:
```bash
git clone https://github.com/your-username/gesture-recognition-tflite.git
cd gesture-recognition-tflite
```
2ï¸âƒ£ Run the script:
```bash
python main.py
```
3ï¸âƒ£ The **webcam** will open, and predictions will appear on the screen.
4ï¸âƒ£ Press **'q'** to quit the application.

---


## ğŸ”¥ Why is This Different from Other Object Classifiers?
### **1ï¸âƒ£ Edge AI Compatibility** ğŸ†
- Designed for **TinyML**-based microcontrollers.
- Runs on **Raspberry Pi, Jetson Nano, and low-power IoT devices**.

### **2ï¸âƒ£ Lightweight Model** âš¡
- Uses **MobileNetV1 Quantized TFLite**, optimized for low-latency inference.
- Runs seamlessly on **Edge Impulse** for easy deployment.

### **3ï¸âƒ£ Real-Time Processing** ğŸ“·
- Uses **OpenCV** for **frame-by-frame analysis**.
- Detects gestures within **milliseconds**.

### **4ï¸âƒ£ Customization & Expandability** ğŸ”„
- Can be **re-trained with custom gestures** using **Edge Impulse**.
- Supports **new models** by replacing `mobilenet_v1_1.0_224_quant.tflite`.

---

## ğŸ“Œ Future Enhancements
ğŸ”¹ Integrate with **Edge Impulse** for real-time model training.
ğŸ”¹ Add **gesture-controlled automation** (e.g., control IoT devices, smart home, etc.).
ğŸ”¹ Deploy on **Raspberry Pi** for a truly **portable edge AI device**.

---

## ğŸ“¢ Contributing
Feel free to contribute! Fork this repo, make improvements, and submit a PR. ğŸš€

ğŸ’¡ **Let's push the boundaries of AI on edge devices!** ğŸ’¡

